{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import keras\n",
    "from keras.layers import Dense,Conv2D, BatchNormalization, Activation,Dropout\n",
    "from keras.layers import AveragePooling2D, Input, Flatten,GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "import keras.backend as K\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import PIL\n",
    "import skimage\n",
    "from keras.models import Model\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            bn-activation-conv (False)\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resnet_v2(input_tensor, depth, num_classes=17):\n",
    "    \"\"\"ResNet Version 2 Model builder [b]\n",
    "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
    "    bottleneck layer\n",
    "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
    "    Second and onwards shortcut connection is identity.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filter maps is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same filter map sizes.\n",
    "    Features maps sizes:\n",
    "    conv1  : 32x32,  16\n",
    "    stage 0: 32x32,  64\n",
    "    stage 1: 16x16, 128\n",
    "    stage 2:  8x8,  256\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 9 != 0:\n",
    "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
    "    # Start model definition.\n",
    "    num_filters_in = 16\n",
    "    num_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "    #inputs = Input(shape=input_shape)\n",
    "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
    "    x = resnet_layer(inputs=input_tensor,\n",
    "                     num_filters=num_filters_in,\n",
    "                     conv_first=True)\n",
    "\n",
    "    # Instantiate the stack of residual units\n",
    "    for stage in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            strides = 1\n",
    "            if stage == 0:\n",
    "                num_filters_out = num_filters_in * 4\n",
    "                if res_block == 0:  # first layer and first stage\n",
    "                    activation = None\n",
    "                    batch_normalization = False\n",
    "            else:\n",
    "                num_filters_out = num_filters_in * 2\n",
    "                if res_block == 0:  # first layer but not first stage\n",
    "                    strides = 2    # downsample\n",
    "\n",
    "            # bottleneck residual unit\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if res_block == 0:\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "\n",
    "        num_filters_in = num_filters_out\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    #y = Flatten()(x)\n",
    "    #outputs = Dense(num_classes,\n",
    "     #               activation='softmax',\n",
    "     #               kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    #model = Model(inputs=inputs, outputs=outputs)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "def focal_loss(classes_num, gamma=2., alpha=.25, e=0.1):\n",
    "    # classes_num contains sample number of each classes\n",
    "    def focal_loss_fixed(target_tensor, prediction_tensor):\n",
    "        '''\n",
    "        prediction_tensor is the output tensor with shape [None, 100], where 100 is the number of classes\n",
    "        target_tensor is the label tensor, same shape as predcition_tensor\n",
    "        '''\n",
    "        import tensorflow as tf\n",
    "        from tensorflow.python.ops import array_ops\n",
    "        from keras import backend as K\n",
    "\n",
    "        #1# get focal loss with no balanced weight which presented in paper function (4)\n",
    "        zeros = array_ops.zeros_like(prediction_tensor, dtype=prediction_tensor.dtype)\n",
    "        one_minus_p = array_ops.where(tf.greater(target_tensor,zeros), target_tensor - prediction_tensor, zeros)\n",
    "        FT = -1 * (one_minus_p ** gamma) * tf.log(tf.clip_by_value(prediction_tensor, 1e-8, 1.0))\n",
    "\n",
    "        #2# get balanced weight alpha\n",
    "        classes_weight = array_ops.zeros_like(prediction_tensor, dtype=prediction_tensor.dtype)\n",
    "\n",
    "        total_num = float(sum(classes_num))\n",
    "        classes_w_t1 = [ total_num / ff for ff in classes_num ]\n",
    "        sum_ = sum(classes_w_t1)\n",
    "        classes_w_t2 = [ ff/sum_ for ff in classes_w_t1 ]   #scale\n",
    "        classes_w_tensor = tf.convert_to_tensor(classes_w_t2, dtype=prediction_tensor.dtype)\n",
    "        classes_weight += classes_w_tensor\n",
    "\n",
    "        alpha = array_ops.where(tf.greater(target_tensor, zeros), classes_weight, zeros)\n",
    "\n",
    "        #3# get balanced focal loss\n",
    "        balanced_fl = alpha * FT\n",
    "        balanced_fl = tf.reduce_sum(balanced_fl)\n",
    "\n",
    "        #4# add other op to prevent overfit\n",
    "        # reference : https://spaces.ac.cn/archives/4493\n",
    "        nb_classes = len(classes_num)\n",
    "        fianal_loss = (1-e) * balanced_fl + e * K.categorical_crossentropy(K.ones_like(prediction_tensor)/nb_classes, prediction_tensor)\n",
    "\n",
    "        return fianal_loss\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape1 = (32, 32, 8)\n",
    "input_shape2 = (32, 32, 10)\n",
    "input_shape3 = (32, 32, 18)\n",
    "input_1 = Input(shape=input_shape1)\n",
    "input_2 = Input(shape=input_shape2)\n",
    "input_3 = Input(shape=input_shape3)\n",
    "L1 = BatchNormalization()(input_1)\n",
    "L2 = BatchNormalization()(input_2)\n",
    "L3 = BatchNormalization()(input_3)\n",
    "L1 = resnet_v2(input_tensor=L1, depth=92)\n",
    "L2 = resnet_v2(input_tensor=L2, depth=92)\n",
    "L3 = resnet_v2(input_tensor=L3, depth=92)\n",
    "\n",
    "#L1 = Conv2D(16, kernel_size=3, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(L1)\n",
    "#L2 = Conv2D(16, kernel_size=3, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(L2)\n",
    "\n",
    "\n",
    "L = keras.layers.concatenate([L1, L2, L3])\n",
    "L = Dense(512, activation='relu')(L)\n",
    "L = BatchNormalization()(L)\n",
    "L = Dropout(0.5)(L)\n",
    "L = Dense(17, activation='softmax', kernel_initializer='he_normal')(L)\n",
    "model = Model(inputs=[input_1, input_2, input_3], outputs=L)\n",
    "class_nums = [5068, 24431, 31693,  8651, 16493, 35290,  3269, 39326,\n",
    "       13584, 11954, 42902,  9514,  9165, 41377,  2392,  7898,\n",
    "       49359]\n",
    "model.compile(loss=[focal_loss(class_nums)], optimizer=Adam(lr=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = h5py.File('./round2_test_b_20190211.h5')\n",
    "test_s1 = np.array(test['sen1'])\n",
    "test_s2 = np.array(test['sen2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = np.zeros((test_s1.shape[0], 17))\n",
    "test_s3 = np.concatenate([test_s1, test_s2], axis=-1)\n",
    "for j in range(5):\n",
    "    model.load_weights('./model_2/1-5-3input/LCZ_model_FOLD_3_input_%s.h5' % str(j))\n",
    "    for i in range(4):\n",
    "        te1 = np.rot90(test_s1,k=i,axes=(1,2))\n",
    "        te2 = np.rot90(test_s2,k=i,axes=(1,2))\n",
    "        te3 = np.rot90(test_s3,k=i,axes=(1,2))\n",
    "        pred += model.predict([te1, te2, te3])\n",
    "    te1 = test_s1[:,::-1,:,:]\n",
    "    te2 = test_s2[:,::-1,:,:]\n",
    "    te3 = test_s3[:,::-1,:,:]\n",
    "    pred += model.predict([te1, te2, te3])\n",
    "    te1 = test_s1[:,:,::-1,:]\n",
    "    te2 = test_s2[:,:,::-1,:]\n",
    "    te3 = test_s3[:,:,::-1,:]\n",
    "    pred += model.predict([te1, te2, te3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Preprocessing(x1, x2):\n",
    "    x1_mean,x1_std = np.mean(x1, axis=(1,2,3)),np.std(x1, axis=(1,2,3))\n",
    "    x2_mean,x2_std = np.mean(x2, axis=(1,2,3)),np.std(x2, axis=(1,2,3))\n",
    "    x1 = (x1-x1_mean.reshape(-1,1,1,1))/x1_std.reshape(-1,1,1,1)\n",
    "    x2 = (x2-x2_mean.reshape(-1,1,1,1))/x2_std.reshape(-1,1,1,1)\n",
    "    return x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predp = np.zeros((test_s1.shape[0], 17))\n",
    "for j in range(5):\n",
    "    model.load_weights('./model_2/LCZ_model_FOLD_3_input_%s_loss-f-92p.h5' % str(j))\n",
    "    for i in range(4):\n",
    "        te1 = np.rot90(test_s1,k=i,axes=(1,2))\n",
    "        te2 = np.rot90(test_s2,k=i,axes=(1,2))\n",
    "        te1, te2 = Preprocessing(te1, te2)\n",
    "        te3 = np.concatenate([te1, te2], axis=-1)\n",
    "        predp += model.predict([te1, te2, te3])\n",
    "    te1 = test_s1[:,::-1,:,:]\n",
    "    te2 = test_s2[:,::-1,:,:]\n",
    "    te1, te2 = Preprocessing(te1, te2)\n",
    "    te3 = np.concatenate([te1, te2], axis=-1)\n",
    "    predp += model.predict([te1, te2, te3])\n",
    "    te1 = test_s1[:,:,::-1,:]\n",
    "    te2 = test_s2[:,:,::-1,:]\n",
    "    te1, te2 = Preprocessing(te1, te2)\n",
    "    te3 = np.concatenate([te1, te2], axis=-1)\n",
    "    predp += model.predict([te1, te2, te3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape1 = (32, 32, 8)\n",
    "input_shape2 = (32, 32, 10)\n",
    "input_shape3 = (32, 32, 18)\n",
    "input_1 = Input(shape=input_shape1)\n",
    "input_2 = Input(shape=input_shape2)\n",
    "input_3 = Input(shape=input_shape3)\n",
    "L1 = BatchNormalization()(input_1)\n",
    "L2 = BatchNormalization()(input_2)\n",
    "L3 = BatchNormalization()(input_3)\n",
    "L1 = resnet_v2(input_tensor=L1, depth=74)\n",
    "L2 = resnet_v2(input_tensor=L2, depth=74)\n",
    "L3 = resnet_v2(input_tensor=L3, depth=74)\n",
    "\n",
    "#L1 = Conv2D(16, kernel_size=3, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(L1)\n",
    "#L2 = Conv2D(16, kernel_size=3, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(L2)\n",
    "\n",
    "\n",
    "L = keras.layers.concatenate([L1, L2, L3])\n",
    "L = Dense(512, activation='relu')(L)\n",
    "L = BatchNormalization()(L)\n",
    "L = Dropout(0.5)(L)\n",
    "L = Dense(17, activation='softmax', kernel_initializer='he_normal')(L)\n",
    "model = Model(inputs=[input_1, input_2, input_3], outputs=L)\n",
    "class_nums = [5068, 24431, 31693,  8651, 16493, 35290,  3269, 39326,\n",
    "       13584, 11954, 42902,  9514,  9165, 41377,  2392,  7898,\n",
    "       49359]\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "model.compile(loss=focal_loss(class_nums), optimizer=Adam(lr=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred74 = np.zeros((test_s1.shape[0], 17))\n",
    "test_s3 = np.concatenate([test_s1, test_s2], axis=-1)\n",
    "for j in range(5):\n",
    "    model.load_weights('./model_2/LCZ_model_FOLD_3_input_%s_loss-f-74.h5' % str(j))\n",
    "    for i in range(4):\n",
    "        te1 = np.rot90(test_s1,k=i,axes=(1,2))\n",
    "        te2 = np.rot90(test_s2,k=i,axes=(1,2))\n",
    "        te3 = np.rot90(test_s3,k=i,axes=(1,2))\n",
    "        pred74 += model.predict([te1, te2, te3])\n",
    "    te1 = test_s1[:,::-1,:,:]\n",
    "    te2 = test_s2[:,::-1,:,:]\n",
    "    te3 = test_s3[:,::-1,:,:]\n",
    "    pred74 += model.predict([te1, te2, te3])\n",
    "    te1 = test_s1[:,:,::-1,:]\n",
    "    te2 = test_s2[:,:,::-1,:]\n",
    "    te3 = test_s3[:,:,::-1,:]\n",
    "    pred74 += model.predict([te1, te2, te3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape1 = (32, 32, 8)\n",
    "input_shape2 = (32, 32, 10)\n",
    "input_shape3 = (32, 32, 18)\n",
    "input_1 = Input(shape=input_shape1)\n",
    "input_2 = Input(shape=input_shape2)\n",
    "input_3 = Input(shape=input_shape3)\n",
    "L1 = BatchNormalization()(input_1)\n",
    "L2 = BatchNormalization()(input_2)\n",
    "L3 = BatchNormalization()(input_3)\n",
    "L1 = resnet_v2(input_tensor=L1, depth=56)\n",
    "L2 = resnet_v2(input_tensor=L2, depth=56)\n",
    "L3 = resnet_v2(input_tensor=L3, depth=56)\n",
    "\n",
    "#L1 = Conv2D(16, kernel_size=3, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(L1)\n",
    "#L2 = Conv2D(16, kernel_size=3, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(L2)\n",
    "\n",
    "\n",
    "L = keras.layers.concatenate([L1, L2, L3])\n",
    "L = Dense(512, activation='relu')(L)\n",
    "L = BatchNormalization()(L)\n",
    "L = Dropout(0.5)(L)\n",
    "L = Dense(17, activation='softmax', kernel_initializer='he_normal')(L)\n",
    "model = Model(inputs=[input_1, input_2, input_3], outputs=L)\n",
    "class_nums = [5068, 24431, 31693,  8651, 16493, 35290,  3269, 39326,\n",
    "       13584, 11954, 42902,  9514,  9165, 41377,  2392,  7898,\n",
    "       49359]\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "model.compile(loss=focal_loss(class_nums), optimizer=Adam(lr=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred56 = np.zeros((test_s1.shape[0], 17))\n",
    "test_s3 = np.concatenate([test_s1, test_s2], axis=-1)\n",
    "for j in range(5):\n",
    "    model.load_weights('./model_2/LCZ_model_FOLD_3_input_%s_loss-f-56.h5' % str(j))\n",
    "    for i in range(4):\n",
    "        te1 = np.rot90(test_s1,k=i,axes=(1,2))\n",
    "        te2 = np.rot90(test_s2,k=i,axes=(1,2))\n",
    "        te3 = np.rot90(test_s3,k=i,axes=(1,2))\n",
    "        pred56 += model.predict([te1, te2, te3])\n",
    "    te1 = test_s1[:,::-1,:,:]\n",
    "    te2 = test_s2[:,::-1,:,:]\n",
    "    te3 = test_s3[:,::-1,:,:]\n",
    "    pred56 += model.predict([te1, te2, te3])\n",
    "    te1 = test_s1[:,:,::-1,:]\n",
    "    te2 = test_s2[:,:,::-1,:]\n",
    "    te3 = test_s3[:,:,::-1,:]\n",
    "    pred56 += model.predict([te1, te2, te3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predss = (pred + pred56 + pred74+predp)/120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = np.zeros((test_s1.shape[0], 17))\n",
    "for i ,ind in enumerate(np.argmax(predss,axis=1)):\n",
    "    result[i][ind] = 1\n",
    "import pandas as pd\n",
    "s = pd.DataFrame(result,dtype='int')\n",
    "s.to_csv('ssssssssssss2.csv', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
